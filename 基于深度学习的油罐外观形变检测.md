# 基于深度学习的油罐外观形变检测

## 一、构建油罐数据集

用到的工具包：

- `os`：提供了一种与操作系统进行交互的方法，例如文件系统操作。
- `numpy`：提供了一种支持大型、多维数组和矩阵运算的Python库。
- `pandas`：提供了高效的数据结构和数据分析工具，用于处理和操作表格数据。
- `cv2`：OpenCV的Python接口，提供了一系列图像处理和计算机视觉相关的函数和算法。
- `tqdm`：用于在Python中添加进度条的库，可用于迭代器和循环中。
- `matplotlib`：提供了绘制各种图表和可视化数据的函数，以及一个交互式绘图环境。`%matplotlib inline`是一个Jupyter Notebook或IPython环境中的魔术命令，它允许将Matplotlib图表直接嵌入到笔记本中，并在执行代码时显示这些图表。
- `shutil`：提供了高级的文件操作函数，例如复制、移动、重命名、删除等。使用`shutil`模块，可以在Python程序中执行文件和文件夹的常规操作，而无需调用操作系统命令。

### 1.收集图像

用python将自己拍摄的油罐视频拆分为图像数据帧并进行分类

![image-20230322101306322](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhenimage-20230322101306322.png)

- normal：正常的油罐图片
- body_broken：瓶身形变的图片
- side_broken：侧部形变图片
- top_broken：顶部形变图片

将图片打包成jiyouguan文件夹

### 2.划分训练集和测试集

```python
test_frac = 0.2  # 测试集比例
random.seed(123) # 随机数种子，便于复现

df = pd.DataFrame()

print('{:^18} {:^18} {:^18}'.format('类别', '训练集数据个数', '测试集数据个数'))

for youguan in classes: # 遍历每个类别

    # 读取该类别的所有图像文件名
    old_dir = os.path.join(dataset_path, youguan)
    images_filename = os.listdir(old_dir)
    random.shuffle(images_filename) # 随机打乱

    # 划分训练集和测试集
    testset_numer = int(len(images_filename) * test_frac) # 测试集图像个数
    testset_images = images_filename[:testset_numer]      # 获取拟移动至 test 目录的测试集图像文件名
    trainset_images = images_filename[testset_numer:]     # 获取拟移动至 train 目录的训练集图像文件名

    # 移动图像至 test 目录
    for image in testset_images:
        old_img_path = os.path.join(dataset_path, youguan, image)         # 获取原始文件路径
        new_test_path = os.path.join(dataset_path, 'val', youguan, image) # 获取 test 目录的新文件路径
        shutil.move(old_img_path, new_test_path) # 移动文件

    # 移动图像至 train 目录
    for image in trainset_images:
        old_img_path = os.path.join(dataset_path, youguan, image)           # 获取原始文件路径
        new_train_path = os.path.join(dataset_path, 'train', youguan, image) # 获取 train 目录的新文件路径
        shutil.move(old_img_path, new_train_path) # 移动文件
    
    # 删除旧文件夹
    assert len(os.listdir(old_dir)) == 0 # 确保旧文件夹中的所有图像都被移动走
    shutil.rmtree(old_dir) # 删除文件夹
    
    # 工整地输出每一类别的数据个数
    print('{:^18} {:^18} {:^18}'.format(youguan, len(trainset_images), len(testset_images)))
    
    # 保存到表格中
    df = df.append({'class':youguan, 'trainset':len(trainset_images), 'testset':len(testset_images)}, ignore_index=True)

# 重命名数据集文件夹
shutil.move(dataset_path, dataset_name+'_split')

# 数据集各类别数量统计表格，导出为 csv 文件
df['total'] = df['trainset'] + df['testset']
df.to_csv('数据量统计.csv', index=False)
```

按训练集和测试集4:1进行划分得到数据集文件夹jiyouguan_split，以下是目录结构



![image-20230322103644251](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhenimage-20230322103644251.png)

### 3.统计图像类别

利用pandas和matplotlib将数据集可视化

- ![image-20230322103733098](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhenimage-20230322103733098.png)
- ![image-20230322104904670](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhenimage-20230322104904670.png)

## 二、模型训练

### 1.环境配置

运行环境：GPU RTX 3060、CUDA v11.3

下载安装pytorch

```python
!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
```

1. 安装 PyTorch：PyTorch 是一个用于机器学习和深度学习的开源框架，它提供了丰富的工具和函数，使得用户可以方便地进行模型的构建、训练和部署等操作。
2. 安装 Torchvision：Torchvision 是 PyTorch 的一个扩展库，提供了一系列计算机视觉相关的工具和函数，如图像数据集加载、图像变换、模型预训练等。
3. 安装 Torchaudio：Torchaudio 是 PyTorch 的另一个扩展库，提供了一系列音频处理相关的工具和函数，如音频数据集加载、音频转换、声音增强等。
4. 使用 `--extra-index-url` 参数指定 PyTorch 软件源地址：PyTorch 的软件源地址不同于一般的 Python 包软件源，因此需要使用该参数指定 PyTorch 软件源地址。其中，`https://download.pytorch.org/whl/cu113` 表示安装适用于 CUDA 11.3 版本的 PyTorch 包。

下载所需要用到的包

```python
!pip install numpy pandas matplotlib seaborn plotly requests tqdm opencv-python pillow wandb
```

- **NumPy**：提供多维数组的支持，包括数学运算和线性代数操作等。
- **Pandas**：提供高性能、易于使用的数据结构和数据分析工具，主要用于数据清洗、转换、分析和可视化。
- **Matplotlib**：提供广泛的数据可视化功能，包括线图、散点图、条形图、饼图等等。
- **Seaborn**：建立在Matplotlib之上的可视化库，提供更高级的统计图形和美观的颜色主题。
- **Plotly**：提供交互式的可视化功能，可以通过web浏览器或者Jupyter notebook交互地探索数据。
- **Requests**：一个用于发起HTTP请求的库，可以用来获取网页数据或API数据。
- **Tqdm**：提供了一个快速简单的进度条，用于在Python命令行界面中实时显示代码执行进度。
- **OpenCV-Python**：一个开源计算机视觉库，提供了许多计算机视觉和图像处理的算法和函数。
- **Pillow**：提供了Python Imaging Library (PIL) 的支持，可以对图像进行各种操作，例如裁剪、旋转、缩放等。
- **Wandb**：一个用于机器学习实验管理的平台，可以方便地记录实验参数、指标、模型和数据等，还提供了实验的可视化和分享功能。

### 2.迁移学习微调训练模型

迁移学习理论知识：

> 迁移学习是一种机器学习技术，它可以利用预先训练好的模型在新任务上进行微调，从而加速新任务的学习和提高性能。在传统机器学习中，通常需要为每个任务单独训练一个模型，这会导致大量的计算和时间成本。而迁移学习可以通过利用已有的模型的知识，来快速训练新模型，从而显著减少训练成本和时间。
>
> 迁移学习方法可以分为以下几类：
>
> 1. 基于特征的迁移学习：将预训练好的模型的特征提取部分作为新模型的特征提取器，然后在新任务的数据集上对模型进行微调，以适应新任务的要求。这种方法适用于新旧任务具有相似特征的情况。
> 2. 基于模型的迁移学习：将预训练好的模型的权重参数作为新模型的初始参数，然后在新任务的数据集上进行微调或训练，以适应新任务的要求。这种方法适用于新旧任务之间具有一定相似性的情况。
> 3. 基于领域的迁移学习：通过比较源任务和新任务之间的相似度，选择适合的源模型进行迁移学习。如果两个任务在领域上相似，则可以使用基于模型的迁移学习方法；如果两个任务在领域上差异较大，则可以使用基于特征的迁移学习方法。
> 4. 增量学习：在预训练模型的基础上，通过不断添加新数据和任务来实现模型的持续学习和更新。这种方法可以视为一种特殊的迁移学习方法，它可以通过预训练模型来快速适应新的数据和任务。
>
> 总之，迁移学习是一种非常重要的机器学习技术，它可以大大提高模型的训练效率和性能，并广泛应用于计算机视觉、自然语言处理等领域。在实践中，选择合适的迁移学习方法需要根据具体的应用场景来确定。

#### （1）预处理

> 在深度学习中，预处理指的是对输入数据进行一系列变换的过程，目的是将输入数据转换为神经网络能够处理的格式，并且增强数据的特征，提高模型的鲁棒性和训练效果。常见的预处理操作包括：
>
> 1. 数据增强：对训练数据进行一系列随机变换，如旋转、裁剪、翻转等，从而生成更多的训练样本，增加数据量，降低过拟合。
> 2. 归一化：将输入数据的像素值缩放到一定范围内，如[0, 1]或[-1, 1]，以便于神经网络进行训练。同时，归一化可以避免特征之间的差异过大，导致梯度消失或梯度爆炸。
> 3. 数据转换：将输入数据转换为神经网络的输入格式，如将图像数据转换为Tensor格式，将文本数据转换为词向量等。
> 4. 标准化：将输入数据按照特定的均值和标准差进行标准化，使得输入数据的分布更加稳定，有助于提高模型的收敛速度和泛化能力。
>
> 预处理可以提高模型的鲁棒性和训练效果，使得模型更加适应不同的数据集和应用场景。同时，预处理可以降低模型的复杂度和训练时间，提高模型的可解释性和可视化效果，并且预处理可以预防过拟合发生。
>

```python
from torchvision import transforms

# 定义训练集图像预处理：首先将图像随机裁剪成224*224的大小，然后进行随机水平翻转增强，接着将图像转换为PyTorch中的Tensor格式，最后将RGB通道的像素值进行归一化
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224), # 随机裁剪224*224大小的图像
    transforms.RandomHorizontalFlip(), # 随机水平翻转增强
    transforms.ToTensor(), # 将图像转换为Tensor格式
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 归一化处理，以便输入到神经网络中
])

# 定义测试集图像预处理-RCTN：首先将图像缩放到256*256的大小，然后从图像中心裁剪出224*224大小的图像，接着将图像转换为PyTorch中的Tensor格式，最后将RGB通道的像素值进行归一化
test_transform = transforms.Compose([
    transforms.Resize(256), # 将图像缩放到256*256大小
    transforms.CenterCrop(224), # 从图像中心裁剪出224*224大小的图像
    transforms.ToTensor(), # 将图像转换为Tensor格式
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], # 用于归一化的均值
        std=[0.229, 0.224, 0.225] # 用于归一化的标准差
    )
])
```

> Tensor是PyTorch中的基本数据类型，支持GPU加速计算。Tensor是一个多维数组，可以表示向量、矩阵、张量等。在深度学习中，通常使用Tensor来存储输入数据、模型参数和输出结果等。

> `mean`和`std`两个数据指的是分别表示在对图像进行归一化处理时使用的均值和标准差。
>
> 在计算机视觉中，我们通常会对输入的图像进行预处理，以提高模型的性能和稳定性。其中一项常用的预处理操作就是归一化，即将像素值进行缩放，使其落在一个较小的范围内，例如[0, 1]或[-1, 1]。归一化的目的是使得输入数据的分布更加均匀，有利于模型更好地学习特征。
>
> 在实际应用中，我们通常会使用某些数据集的统计信息来进行归一化。对于图像数据，一种常见的方法是计算整个数据集的像素均值和标准差，然后将每个像素值减去均值再除以标准差，以使其分布在一个较小的范围内。这个过程通常可以通过调用现有的函数或库来实现，例如PyTorch中的`transforms.Normalize`函数。
>
> 这里使用的均值和标准差是在ImageNet数据集上计算得到的，可以在训练模型时进行归一化。但是，对于其他数据集和应用，可能需要重新计算均值和标准差，或者使用不同的归一化方法。

#### （2）建立索引关系

```python
# 各类别名称
class_names = train_dataset.classes
n_class = len(class_names)
idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}
np.save('idx_to_labels.npy', idx_to_labels)# 保存为本地的 npy 文件
```

idx_to_labels的索引为`{0: 'body_broken', 1: 'normal', 2: 'side_broken', 3: 'top_broken'}`

#### （3）数据加载器DataLoader

```python
from torch.utils.data import DataLoader

BATCH_SIZE = 32

# 训练集的数据加载器，用于批量加载训练集数据
train_loader = DataLoader(train_dataset,  # 加载的训练集数据
                          batch_size=BATCH_SIZE,  # 批量数据大小
                          shuffle=True,  # 是否打乱数据
                          num_workers=4  # 用于数据读取的线程数
                         )

# 测试集的数据加载器，用于批量加载测试集数据
test_loader = DataLoader(test_dataset,  # 加载的测试集数据
                         batch_size=BATCH_SIZE,  # 批量数据大小
                         shuffle=False,  # 是否打乱数据
                         num_workers=4  # 用于数据读取的线程数
                        )
```

> DataLoader 是 PyTorch 中用于批量加载数据的类
>
> BATCH_SIZE 表示每个批次中包含的样本数量
>
> train_loader 和 test_loader 分别代表训练集和测试集的数据加载器
>
> shuffle 参数表示是否需要打乱数据
>
> num_workers 参数表示数据读取所需的线程数。

#### （4）载入训练模型

##### ①导入工具包

```python
from torchvision import models
import torch.optim as optim
from torch.optim import lr_scheduler
```

> 导入PyTorch中的模块和函数，其中：
>
> - `from torchvision import models`：导入PyTorch官方提供的深度学习模型Torchvision中的models模块。该模块包含了一系列预训练好的深度学习模型，本次训练采用了resnet18训练模型。
> - `import torch.optim as optim`：导入PyTorch中的优化器模块，这个模块中包含了各种优化器算法的实现，本次采用了Adam优化器。
> - `from torch.optim import lr_scheduler`：导入PyTorch中的学习率调度器模块，该模块提供了各种学习率衰减策略的实现，本次采用了StepLR策略。
>
> 这些模块和函数的作用分别为：
>
> - `models`：提供了预训练好的深度学习模型，可以用于特征提取、微调等任务。
> - `optim`：提供了各种优化器算法的实现，可以用于优化深度学习模型的参数，使其更好地拟合训练数据。
> - `lr_scheduler`：提供了各种学习率调度器的实现，可以用于自动调整模型的学习率，使其更好地适应训练数据的分布和模型训练的进度。
>
> 在深度学习模型的训练中，优化器和学习率调度器通常都是非常重要的组件。优化器用于更新模型的参数，而学习率调度器则用于调整优化器的学习率，以适应模型训练过程中的不同需求。PyTorch提供了各种优化器和学习率调度器的实现，方便用户快速构建和训练深度学习模型。

##### ②训练配置-微调训练所有层

```python
# 载入预训练的ResNet-18模型
model = models.resnet18(pretrained=True)

# 将模型的全连接层替换成适应当前任务的新全连接层
model.fc = nn.Linear(model.fc.in_features, n_class)

# 创建优化器Adam，用于更新模型参数
optimizer = optim.Adam(model.parameters())

```

> - `models.resnet18(pretrained=True)` 载入PyTorch内置的预训练的ResNet-18模型，参数 `pretrained=True` 表示使用预训练好的模型，可以提高模型的泛化能力。
> - `model.fc = nn.Linear(model.fc.in_features, n_class)` 将模型的全连接层替换成适应当前任务的新全连接层。其中 `nn.Linear` 是PyTorch内置的线性层，用于定义全连接层。`model.fc.in_features` 是ResNet-18模型全连接层的输入特征数，`n_class` 是当前任务的类别数，用于指定新全连接层的输出特征数。
> - `optim.Adam(model.parameters())` 创建一个Adam优化器，用于更新模型参数。其中 `model.parameters()` 获取模型的可学习参数。Adam是一种常用的优化器，可根据梯度自适应地调整学习率，从而实现更快的训练速度和更好的性能。



> 为什么采用resnet18：由于机油罐的数据集数量并不庞大，而resnet18是一种较小的网络结构，具有较少的层数和较少的参数，因此它通常比resnet152等大型模型更容易训练，并且在计算资源和时间有限的情况下更加高效。resnet18也比较适合在小数据集上进行训练，因为在小数据集上训练大型模型可能会导致过拟合。



> 为什么使用的是 `optimizer = optim.Adam(model.parameters())` 而不是`optimizer = optim.Adam(model.fc.parameters())`?
>
> `optimizer = optim.Adam(model.fc.parameters())` 只更新模型的最后一层（全连接层）的参数，而 `optimizer = optim.Adam(model.parameters())` 更新整个模型的所有参数。由于机油罐的数据集相对较小且并不常见，所以需要更多的微调提升训练的准确性。
>
> 通常情况下，对于使用预训练模型进行微调（fine-tuning）的情况，我们会冻结预训练模型的参数，只更新最后一层的参数。这是因为预训练模型的参数已经在大规模数据集上得到了充分训练，具有较强的泛化能力，而最后一层需要根据具体的任务进行调整，以使得模型输出与任务的期望输出尽量接近。因此，只更新最后一层的参数可以减少训练时间，同时还可以防止过拟合。



> 什么是过拟合：过拟合（overfitting）是指在机器学习模型中，模型在训练数据上表现良好，但在测试数据上表现较差的现象。过拟合通常发生在模型太复杂或训练数据过少的情况下。过拟合是一种高分低能的表现，过拟合的一个简单例子就是考试作弊。当你复习一个考试，但只准备了几道题，然后在考试中恰巧出现了这些题目，你可能会获得很高的分数。但这并不意味着你真正掌握了这门学科，因为你并没有准备其他的题目，也无法回答与准备好的题目不同的问题。这种情况就好比过拟合，你的“模型”只学习了部分的数据或者样本，而无法泛化到其他的数据或者样本上。当遇到未知的数据或问题时，你的表现就会变得很糟糕。在机器学习中，我们需要保证模型能够泛化到新的数据上，而不仅仅是在训练数据上表现良好，从而避免过拟合的问题。

##### ③训练配置-策略

```python
model = model.to(device)

# 交叉熵损失函数
criterion = nn.CrossEntropyLoss() 

# 训练轮次 Epoch
EPOCHS = 30

# 学习率降低策略
lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
```

> 损失函数是什么？
>
> 损失函数是机器学习中一个重要的概念，用于衡量模型的预测结果与真实标签之间的差异。在监督学习中，通常会将训练数据划分为输入和输出两部分，其中输入是样本的特征，输出是样本的标签。模型的训练过程就是通过最小化损失函数来调整模型的参数，使得模型的预测结果更加接近真实标签。
>
> 在分类问题中，常用的损失函数包括交叉熵损失函数、负对数似然损失函数等。在回归问题中，常用的损失函数包括均方误差损失函数、平均绝对误差损失函数等。
>
> 交叉熵损失函数通常用于多分类问题，它基于信息论中的概念，衡量模型的预测结果与真实标签之间的差异。负对数似然损失函数也用于多分类问题，它是交叉熵损失函数的一个特例。均方误差损失函数通常用于回归问题，它衡量模型的预测结果与真实标签之间的平方差，越小表示模型的拟合效果越好。平均绝对误差损失函数也用于回归问题，它衡量模型的预测结果与真实标签之间的绝对差，越小表示模型的拟合效果越好。
>
> 选择合适的损失函数可以帮助模型更好地学习任务的规律，提高模型的拟合效果。同时，在模型训练过程中，也需要注意选择合适的优化算法和学习率等超参数，以达到更好的训练效果。



> 学习率衰减策略，使用StepLR学习率衰减器，每5个epoch将学习率乘以0.5。
>
> 学习率衰减策略是深度学习中常用的优化方法之一，通过在训练过程中逐步降低学习率，使得模型在接近收敛时能够更好地探索局部最优解，从而提高模型性能和泛化能力。
>
> 在上面的代码中，使用了StepLR学习率衰减器。该衰减器按照一定的步长(step_size)将学习率进行衰减，衰减率由gamma参数控制。具体来说，每step_size个epoch，将当前的学习率乘以gamma，这样就能够逐渐降低学习率，使模型更好地收敛。
>
> 在这里，使用了step_size=5和gamma=0.5，意味着在每5个epoch时将当前学习率乘以0.5，从而逐渐减小学习率。这种学习率衰减策略可以帮助模型更快地收敛，同时避免过拟合。

#### （5）训练和评估函数

##### ①训练函数

```python
def train_one_batch(images, labels):
    '''
    运行一个 batch 的训练，返回当前 batch 的训练日志
    '''
    
    # 将数据和标签移到指定设备上
    images = images.to(device)
    labels = labels.to(device)
    
    # 输入模型，执行前向预测
    outputs = model(images)
    
    # 由logit计算当前 batch 中，每个样本的平均交叉熵损失函数值
    loss = criterion(outputs, labels)
    
    # 优化更新权重
    optimizer.zero_grad() # 清空梯度
    loss.backward() # 反向传播
    optimizer.step() # 优化器更新权重
    
    # 获取当前 batch 的标签类别和预测类别
    _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别
    preds = preds.cpu().numpy() # 将预测类别转为 numpy 数组
    loss = loss.detach().cpu().numpy() # 将损失函数值转为 numpy 数组
    outputs = outputs.detach().cpu().numpy() # 将模型输出转为 numpy 数组
    labels = labels.detach().cpu().numpy() # 将标签转为 numpy 数组
    
    # 创建当前 batch 的训练日志
    log_train = {}
    log_train['epoch'] = epoch # 当前 epoch
    log_train['batch'] = batch_idx # 当前 batch
    log_train['train_loss'] = loss # 当前 batch 中的损失函数值
    log_train['train_accuracy'] = accuracy_score(labels, preds) # 当前 batch 中的准确率
    
    return log_train

```



##### ②评估函数

```python
def evaluate_testset():
    '''
    在整个测试集上评估，返回分类评估指标日志
    '''

    loss_list = []   # 创建一个空列表用于存储损失值
    labels_list = []  # 创建一个空列表用于存储标签类别
    preds_list = []   # 创建一个空列表用于存储预测类别
    
    with torch.no_grad():  # 关闭梯度计算，加速推理
        for images, labels in test_loader: # 生成一个 batch 的数据和标注
            images = images.to(device)  # 将数据移动到设备上进行计算
            labels = labels.to(device)
            outputs = model(images) # 输入模型，执行前向预测

            # 获取整个测试集的标签类别和预测类别
            _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别
            preds = preds.cpu().numpy()  # 将预测类别移动到cpu上并转化为numpy数组
            loss = criterion(outputs, labels) # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值
            loss = loss.detach().cpu().numpy() # 将损失值移动到cpu上并转化为numpy数组
            outputs = outputs.detach().cpu().numpy() # 将输出结果移动到cpu上并转化为numpy数组
            labels = labels.detach().cpu().numpy() # 将标签类别移动到cpu上并转化为numpy数组

            loss_list.append(loss) # 将损失值添加到损失列表中
            labels_list.extend(labels) # 将标签类别添加到标签列表中
            preds_list.extend(preds) # 将预测类别添加到预测列表中
        
    log_test = {}  # 创建一个字典，用于存储分类评估指标
    log_test['epoch'] = epoch  # 记录当前的epoch数
    
    # 计算分类评估指标
    log_test['test_loss'] = np.mean(loss)  # 计算测试集平均损失值
    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)  # 计算测试集的准确率
    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')  # 计算测试集的精确率
    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')  # 计算测试集的召回率
    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')  # 计算测试集的f1-score
    
    return log_test  # 返回分类评估指标日志

```

#### （6）运用工具wandb（Weights&biases)进行数据可视化

> 如何登录wandb：
>
> 1.安装 wandb：pip install wandb
>
> 2.登录 wandb：在命令行中运行wandb login
>
> 3.按提示复制粘贴API Key至命令行中

##### 创建可视化项目

```python
import wandb

wandb.init(project='毕业设计', name=time.strftime('%m%d%H%M%S'))
```

![image-20230322171922700](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhenimage-20230322171922700.png)

各指标数据

- train_accuracy和test_accuracy：训练和测试准确度分别表示模型在训练和测试阶段的分类准确率，即模型预测正确的样本数与总样本数的比值。准确率越高，表示模型性能越好。![train_accuracy](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhentrain_accuracy.png)![test_accuracy](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhentest_accuracy.png)

- train_loss和test_loss：训练和测试损失分别表示训练和测试阶段的平均损失，损失值越小，表示模型拟合得越好。![train_loss](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhentrain_loss.png)![train_loss](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhentest_loss.png)
- test_precision：精确率是指模型预测为正例的样本中，实际为正例的比例。对于二分类问题，它等于真正例数除以真正例数加上假正例数，对于多分类问题，需要对每个类别计算精确率。精确率高表示模型对于正例的识别能力强。![test_precision](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhentest_precision.png)
- test_recall：召回率是指实际为正例的样本中，模型正确预测为正例的比例。对于二分类问题，它等于真正例数除以真正例数加上假反例数，对于多分类问题，需要对每个类别计算召回率。召回率高表示模型对于正例的识别率高。![test_recall](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhentest_recall.png)
- test_f1-score：F1分数是精确率和召回率的调和平均数，是综合评估模型性能的指标。F1分数高表示模型能够同时兼顾精确率和召回率。在不同的应用场景中，精确率或召回率可能更为重要，因此需要根据实际情况选择合适的指标。![test_f1-score](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/oss-cn-shenzhentest_f1-score.png)

也可访问下面的网站

https://api.wandb.ai/links/youguanai/7xwwyn3b

#### （7）进行30个epoch的训练

```python
for epoch in range(1, EPOCHS+1):
    
    print(f'Epoch {epoch}/{EPOCHS}')
    
    ## 训练阶段
    model.train()
    for images, labels in tqdm(train_loader): # 获得一个 batch 的数据和标注
        batch_idx += 1
        log_train = train_one_batch(images, labels)
        df_train_log = df_train_log.append(log_train, ignore_index=True)
        wandb.log(log_train)
        
    lr_scheduler.step()

    ## 测试阶段
    model.eval()
    log_test = evaluate_testset()
    df_test_log = df_test_log.append(log_test, ignore_index=True)
    wandb.log(log_test)
    
    # 保存最新的最佳模型文件
    if log_test['test_accuracy'] > best_test_accuracy: 
        # 删除旧的最佳模型文件(如有)
        old_best_checkpoint_path = 'checkpoints/best-{:.3f}.pth'.format(best_test_accuracy)
        if os.path.exists(old_best_checkpoint_path):
            os.remove(old_best_checkpoint_path)
        # 保存新的最佳模型文件
        new_best_checkpoint_path = 'checkpoints/best-{:.3f}.pth'.format(log_test['test_accuracy'])
        torch.save(model, new_best_checkpoint_path)
        print('保存新的最佳模型', 'checkpoints/best-{:.3f}.pth'.format(best_test_accuracy))
        best_test_accuracy = log_test['test_accuracy']
```

进行30epoch的训练和测试，并保存最好的训练模型，本次保存的训练模型为`best-1.000.pth`

评估指标为`{'epoch': 30, 'test_loss': 0.0007636015, 'test_accuracy': 1.0, 'test_precision': 1.0, 'test_recall': 1.0, 'test_f1-score': 1.0}`

## 三、图像预测

### 1.导入训练模型

```python
model = torch.load('checkpoints/best-1.000.pth')
model = model.eval().to(device)
```

导入已经训练好的`best-1.000.pth`模型,并调成评估状态。

### 2.预处理、前向预测

```python
input_img = test_transform(img_pil) # 预处理
input_img = input_img.unsqueeze(0).to(device)

pred_logits = model(input_img)# 执行前向预测，得到所有类别的 logit 预测分数
pred_softmax = F.softmax(pred_logits, dim=1) # 对 logit 分数做 softmax 运算
```

> `pred_logits = model(input_img)`：首先，通过输入图像 `input_img` 作为模型的输入，调用训练好的深度学习模型 `model` 进行前向预测。在前向预测中，图像会经过多个层和操作，在模型中逐渐被转换成一个向量，该向量表示图像最终被模型预测为属于每个类别的概率分数（也称为“logit”）。
>
> `pred_softmax = F.softmax(pred_logits, dim=1)`：接着，对于每个类别的预测分数（logit），应用 softmax 函数对其进行规范化，得到该类别的概率预测值。softmax 函数将 logit 分数映射到 [0,1] 的概率分布上，其中每个类别的概率值表示该图像属于该类别的可能性大小。在这个例子中，对预测结果进行 softmax 函数的操作后，`pred_softmax` 变量将包含所有类别的概率预测值。

得到的`softmax`结果为![image-20230322210238719](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322210238719.png)

### 3.输出图片处理结果

以此图片为例![54321](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/54321.jpg)

#### ①用pillow输出柱状图

```python
plt.figure(figsize=(22, 10))

x = idx_to_labels.values()
y = pred_softmax.cpu().detach().numpy()[0] * 100
width = 0.45 # 柱状图宽度

ax = plt.bar(x, y, width)

plt.bar_label(ax, fmt='%.2f', fontsize=15) # 置信度数值
plt.tick_params(labelsize=20) # 设置坐标文字大小

plt.title(img_path, fontsize=30)
plt.xticks(rotation=45) # 横轴文字旋转
plt.xlabel('类别', fontsize=20)
plt.ylabel('置信度', fontsize=20)
plt.show()
```

![image-20230322211653300](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322211653300.png)

#### ②将分类结果写在图片上

```python
n = 4
top_n = torch.topk(pred_softmax, n) # 取置信度最大的 n 个结果
pred_ids = top_n[1].cpu().detach().numpy().squeeze() # 解析出类别
confs = top_n[0].cpu().detach().numpy().squeeze() # 解析出置信度

draw = ImageDraw.Draw(img_pil)
for i in range(n):
    class_name = idx_to_labels[pred_ids[i]] # 获取类别名称
    confidence = confs[i] * 100 # 获取置信度
    text = '{:<15} {:>.4f}'.format(class_name, confidence)
    print(text)
    
    # 文字坐标，中文字符串，字体，rgba颜色
    draw.text((50, 100 + 50 * i), text, font=font, fill=(255, 0, 0, 1))
```

![下载](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/%E4%B8%8B%E8%BD%BD.png)

#### ③图片预测结果

![image-20230322212131006](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322212131006.png)

更多组测试结果

- ![image-20230322212401843](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322212401843.png)
- ![image-20230322212509825](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322212509825.png)
- ![image-20230322212625395](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322212625395.png)
- ![image-20230322212827879](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322212827879.png)
- ![image-20230322212952437](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322212952437.png)
- ![image-20230322213344830](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/image-20230322213344830.png)

## 四、视频预测

### 1.下载安装mmcv

```python
!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.10.0/index.html
```

> `mmcv` 是一个深度学习计算机视觉开发工具箱，提供了各种基本图像和视频处理工具、模型构建和训练所需的各种组件，同时也支持各种图像和视频处理任务中常见的数据集格式。这个工具箱使用Python实现，并基于PyTorch和OpenCV等常见的计算机视觉库进行开发。
>
> 
>
> 本次主要用于将视频进行拆帧后进行图像预测处理，然后进行组帧成视频

### 2.预处理，前向预测

与图像预测一致

```python
#导入训练好的模型
model = torch.load('checkpoints/best-1.000.pth')
model = model.eval().to(device)


#图像预处理
from torchvision import transforms
# 测试集图像预处理-RCTN：缩放裁剪、转 Tensor、归一化
test_transform = transforms.Compose([transforms.Resize(256),
                                     transforms.CenterCrop(224),
                                     transforms.ToTensor(),
                                     transforms.Normalize(
                                         mean=[0.485, 0.456, 0.406], 
                                         std=[0.229, 0.224, 0.225])
                                    ])
                                    
#图像分类预测函数
def pred_single_frame(img, n=5):
    '''
    输入摄像头画面bgr-array，输出前n个图像分类预测结果的图像bgr-array
    '''
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR 转 RGB
    img_pil = Image.fromarray(img_rgb) # array 转 pil
    input_img = test_transform(img_pil).unsqueeze(0).to(device) # 预处理
    pred_logits = model(input_img) # 执行前向预测，得到所有类别的 logit 预测分数
    pred_softmax = F.softmax(pred_logits, dim=1) # 对 logit 分数做 softmax 运算
    
    top_n = torch.topk(pred_softmax, n) # 取置信度最大的 n 个结果
    pred_ids = top_n[1].cpu().detach().numpy().squeeze() # 解析出类别
    confs = top_n[0].cpu().detach().numpy().squeeze() # 解析出置信度
    
    # 在图像上写字
    draw = ImageDraw.Draw(img_pil)
    # 在图像上写字
    for i in range(len(confs)):
        pred_class = idx_to_labels[pred_ids[i]]
        text = '{:<15} {:>.3f}'.format(pred_class, confs[i])
        # 文字坐标，中文字符串，字体，rgba颜色
        draw.text((50, 100 + 50 * i), text, font=font, fill=(255, 0, 0, 1))
        
    img_bgr = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR) # RGB转BGR
        
    return img_bgr, pred_softmax
```



### 3.视频处理

#### ①.读入视频进行拆帧组帧

```python
# 创建临时文件夹，存放每帧结果
temp_out_dir = time.strftime('%Y%m%d%H%M%S')
os.mkdir(temp_out_dir)
print('创建临时文件夹 {} 用于存放每帧预测结果'.format(temp_out_dir))

# 读入待预测视频
imgs = mmcv.VideoReader(input_video)

prog_bar = mmcv.ProgressBar(len(imgs))

# 对视频逐帧处理
for frame_id, img in enumerate(imgs):
    
    ## 处理单帧画面
    img, pred_softmax = pred_single_frame(img, n=2)
    img = pred_single_frame_bar(img)
    
    prog_bar.update() # 更新进度条

# 把每一帧串成视频文件
mmcv.frames2video(temp_out_dir, 'output/output_bar.mp4', fps=imgs.fps, fourcc='mp4v')

shutil.rmtree(temp_out_dir) # 删除存放每帧画面的临时文件夹
print('删除临时文件夹', temp_out_dir)
```



#### ②.图像识别

```python
def pred_single_frame_bar(img):
    '''
    输入pred_single_frame函数输出的bgr-array，加柱状图，保存
    '''
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR 转 RGB
    fig = plt.figure(figsize=(18,6))
    # 绘制左图-视频图
    ax1 = plt.subplot(1,2,1)
    ax1.imshow(img)
    ax1.axis('off')
    # 绘制右图-柱状图
    ax2 = plt.subplot(1,2,2)
    x = idx_to_labels.values()
    y = pred_softmax.cpu().detach().numpy()[0] * 100
    ax2.bar(x, y, alpha=0.5, width=0.3, color='yellow', edgecolor='red', lw=3)
    plt.xlabel('类别', fontsize=20)
    plt.ylabel('置信度', fontsize=20)
    ax2.tick_params(labelsize=16) # 坐标文字大小
    plt.ylim([0, 100]) # y轴取值范围
    plt.xlabel('类别',fontsize=25)
    plt.ylabel('置信度',fontsize=25)
    plt.title('图像分类预测结果', fontsize=30)
    plt.xticks(rotation=90) # 横轴文字旋转
    
    plt.tight_layout()
    fig.savefig(f'{temp_out_dir}/{frame_id:06d}.jpg')
    # 释放内存
    fig.clf()
    plt.close()
    gc.collect()
```

与图像预测模块几乎一致

### 4.视频预测结果

以下是将视频文件预测结果（已转gif）

![output_bar(1)](https://typora-xiaoyongyi.oss-cn-shenzhen.aliyuncs.com/img_for_typora/output_bar(1).gif)

